---
layout: post
title: "Getting Started with Boto3"
categories: [AWS, boto3]
tags: [AWS, boto3]
---

<p align="center"><img src="/assets/img/post_img/boto3_1.png"></p>

**Boto3** is AWS’s official Python SDK. I’m documenting the basics here (tested with Boto3 1.21.7) as preparation for automating AWS pipelines.

<br>

### Quick Start

The SDK consists of two main packages:
- **botocore** – shared functionality between the SDK and AWS CLI.
- **boto3** – the high-level Python interface (what people usually mean when they say “Boto3”).

Use Python 3.6 or newer.

Install:

```bash
pip install boto3
```

Specify versions if needed:

```bash
pip install boto3==1.0.0
pip install boto3>=1.15.0
pip install boto3<=1.15.3
```

Include the AWS Common Runtime (CRT) extras if desired:

```bash
pip install boto3[crt]
```

<br>

### Credentials

Create an IAM user via the AWS console and note the `aws_access_key_id` and `aws_secret_access_key`.store them securely—environment variables work well.

<br>

### S3 Client Example

```python
import os
import boto3

AWS_KEY_ID = os.environ.get("AWS_KEY_ID")
AWS_SECRET_KEY = os.environ.get("AWS_SECRET_KEY")

s3 = boto3.client(
    "s3",
    region_name="ap-northeast-2",
    aws_access_key_id=AWS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_KEY,
)
```

<br>

### Common S3 Operations

**Create a bucket** (note the regional config and unique name; avoid underscores):

```python
s3.create_bucket(
    Bucket="jb-boto3-test12",
    CreateBucketConfiguration={"LocationConstraint": "ap-northeast-2"},
)
```

**List buckets**:

```python
resp = s3.list_buckets()
for bucket in resp["Buckets"]:
    print(bucket["Name"])
```

**Delete a bucket**:

```python
s3.delete_bucket(Bucket="jb-boto3-test12")
```

**Upload an object**:

```python
s3.upload_file(
    Bucket="semogong",
    Filename="test_boto3.csv",   # local file
    Key="test_boto3.csv",        # S3 object key
)
```

**List objects** (with optional filters):

```python
s3.list_objects(Bucket="semogong")
# s3.list_objects(Bucket="semogong", MaxKeys=2, Prefix="test_")
```

**Inspect a single object**:

```python
s3.head_object(Bucket="semogong", Key="test_boto3.csv")
```

**Download**:

```python
s3.download_file(
    Bucket="semogong",
    Key="test_boto3.csv",
    Filename="download.csv",
)
```

**Delete an object**:

```python
s3.delete_object(Bucket="semogong", Key="test_boto3.csv")
```

<br>

### Managing ACLs

Set ACLs on existing objects:

```python
s3.put_object_acl(
    Bucket="semogong",
    Key="test_boto3.csv",
    ACL="public-read",
)
```

Or specify ACLs during upload:

```python
s3.upload_file(
    Bucket="semogong",
    Filename="test_boto3.csv",
    Key="test_boto3.csv",
    ExtraArgs={"ACL": "public-read"},
)
```

Remember to enable ACLs at the bucket level if required. With these basics, you can automate S3 workflows entirely from Python.
